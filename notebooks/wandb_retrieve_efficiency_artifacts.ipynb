{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieve a wandb artifact of results and process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import wandb\n",
        "import yaml\n",
        "import pickle\n",
        "import tempfile\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from src.utils2 import process_results\n",
        "\n",
        "with open('../wandb.yaml') as file:\n",
        "    wandb_data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_data['wandb_key'] \n",
        "wandb_entity = str(wandb_data['wandb_entity'])\n",
        "\n",
        "# your wandb project name\n",
        "project_name = 'dips_data_efficiency'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process(overall_result_dicts, numIters, subsample_res, prop_check, method='pseudo'):\n",
        "    results = process_results(results_list=overall_result_dicts,numIters=numIters, end_score=True)\n",
        "    sample_processed = {}\n",
        "\n",
        "    for subsample_prop in prop_check:\n",
        "        sample_processed[subsample_prop] = process_results(results_list=subsample_res[subsample_prop],numIters=numIters, end_score=True)\n",
        "\n",
        "\n",
        "    our_scores= []\n",
        "    pseudo_score = []\n",
        "    final_props = []\n",
        "    for subsample_prop in prop_check:\n",
        "        try:\n",
        "            score = sample_processed[subsample_prop][method]['dips_full_mean']\n",
        "            our_scores.append(score)\n",
        "\n",
        "            score = sample_processed[subsample_prop][method]['vanilla_mean']\n",
        "            pseudo_score.append(score)\n",
        "\n",
        "            final_props.append(subsample_prop)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "    score = results[method]['dips_full_mean']\n",
        "    our_scores.append(score)\n",
        "\n",
        "    score = results[method]['vanilla_mean']\n",
        "    pseudo_score.append(score)\n",
        " \n",
        "    return pseudo_score, our_scores, final_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded compas, 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded compas, 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded compas, 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded compas, 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:08,  8.08s/it]\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded covid, 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded covid, 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded covid, 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded covid, 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:17,  8.87s/it]\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded adult, 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded adult, 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded adult, 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded adult, 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [00:25,  8.64s/it]\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded maggic, 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded maggic, 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded maggic, 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded maggic, 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [00:34,  8.53s/it]\n"
          ]
        }
      ],
      "source": [
        "# minimum sweeps\n",
        "sweeps = [('compas', '1.0'), ('covid', '0.66'),  ('adult', '0.66'), ('maggic', '0.66')]\n",
        "\n",
        "# all sweeps\n",
        "# sweeps = [('seer', '1.0'), ('adult', '0.66'), ('cutract', '1.0'), ('covid', '0.66'),   ('maggic', '0.66'), ('German-credit', '1.0'),(\"compas\", \"1.0\"), (\"agaricus-lepiota\", '1.0'),  (\"higgs\", \"0.1\"),   ('drug', '0.1'), (\"blog\", \"0.2\"), (\"credit\", \"1.0\")]\n",
        "\n",
        "# either 'ups' or 'pseudo'\n",
        "method = 'ups'\n",
        "\n",
        "selector = 'dips'\n",
        "\n",
        "ours_all_data = []\n",
        "vanilla_all_data = []\n",
        "\n",
        "for idx_sweep, sweep in tqdm(enumerate(sweeps)):\n",
        "    try:\n",
        "        files=0\n",
        "        prop_data = sweep[1]\n",
        "        dataset_name = sweep[0]\n",
        "        numTrials = 5\n",
        "        seed = 0\n",
        "        data_iq_xthresh = \"0.0\"\n",
        "\n",
        "        results_dfs = []\n",
        "        metainfo_list = []\n",
        "        min_list = []\n",
        "        max_list = []\n",
        "\n",
        "        our_scores_all = []\n",
        "        pseudo_score_all = []\n",
        "        our_scores_se_all = []\n",
        "        pseudo_score_se_all = []\n",
        "        \n",
        "\n",
        "        for idx, seed in enumerate([0, 10, 42, 100, 1000]):\n",
        "            try:\n",
        "            \n",
        "                temp_dir = tempfile.TemporaryDirectory()\n",
        "\n",
        "                metainfo = f\"{dataset_name}_{prop_data}_{data_iq_xthresh}_{numTrials}_{seed}\"\n",
        "                metainfo_list.append(metainfo)\n",
        "\n",
        "                api = wandb.Api()\n",
        "                artifact = api.artifact(f'{wandb_entity}/{project_name}/sample_dict_{metainfo}:latest', type='pickle')\n",
        "                artifact_dir = artifact.download(root=temp_dir.name)\n",
        "\n",
        "\n",
        "                with open(artifact_dir + f\"/sample_dict_{metainfo}.pkl\", \"rb\") as f:\n",
        "                    subsample_res = pickle.load(f)\n",
        "                temp_dir.cleanup()\n",
        "\n",
        "\n",
        "                temp_dir = tempfile.TemporaryDirectory()\n",
        "\n",
        "\n",
        "                api = wandb.Api()\n",
        "                artifact = api.artifact(f'{wandb_entity}/{project_name}/results_dict_{metainfo}:latest', type='pickle')\n",
        "                artifact_dir = artifact.download(root=temp_dir.name)\n",
        "\n",
        "\n",
        "                with open(artifact_dir + f\"/results_dict_{metainfo}.pkl\", \"rb\") as f:\n",
        "                    overall_result_dicts = pickle.load(f)\n",
        "                temp_dir.cleanup()\n",
        "\n",
        "                prop_check = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "                numIters = 5\n",
        "                pseudo_score, our_scores,  final_props = process(overall_result_dicts, numIters, subsample_res, prop_check, method)\n",
        "                \n",
        "                our_scores_all.append(our_scores)\n",
        "                pseudo_score_all.append(pseudo_score)\n",
        "\n",
        "                print(f\"Loaded {dataset_name}, {files}\")\n",
        "\n",
        "                files+=1\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "\n",
        "        our_scores_all = np.array(our_scores_all)\n",
        "        pseudo_score_all = np.array(pseudo_score_all)\n",
        "\n",
        "        from scipy.stats import sem\n",
        "        our_scores = np.mean(our_scores_all, axis=0)\n",
        "        pseudo_score = np.mean(pseudo_score_all, axis=0)\n",
        "\n",
        "        try:\n",
        "            our_scores_se = sem(our_scores_all, axis=0)\n",
        "            pseudo_score_se = sem(pseudo_score_all, axis=0)\n",
        "        except:\n",
        "            our_scores_se = np.std(our_scores_all, axis=0)\n",
        "            pseudo_score_se = np.std(pseudo_score_all, axis=0)\n",
        "        \n",
        "        ours_all_data.append(our_scores)\n",
        "        vanilla_all_data.append(pseudo_score)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "# compute the norm vs the highest vanilla method value (i.e. relative gain)\n",
        "norms = np.array(vanilla_all_data)[:,-1]\n",
        "ours_gain = deepcopy(np.array(ours_all_data))\n",
        "vanilla_gain = deepcopy(np.array(vanilla_all_data))\n",
        "\n",
        "for i in range(vanilla_gain.shape[0]):\n",
        "    vanilla_gain[i,:] = vanilla_gain[i,:]-norms[i]\n",
        "    ours_gain[i, :] = ours_gain[i,:]-norms[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pickle to plot later\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(f\"../results/efficiency_norms_{selector}_{method}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(norms, f)\n",
        "\n",
        "with open(f\"../results//vanilla_efficiency_{selector}_{method}.pkl\", 'wb') as file:\n",
        "    pickle.dump(vanilla_gain, file)\n",
        "\n",
        "with open(f\"../results/ours_efficiency_{selector}_{method}.pkl\", 'wb') as file:\n",
        "    pickle.dump(ours_gain, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM1YDnCNhxzVnGQY13tScTc",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "demo_ConfidentSinkhornAllocation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ssl_dcai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
